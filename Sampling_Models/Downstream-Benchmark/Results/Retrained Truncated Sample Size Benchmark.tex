\begin{tabular}{llrrrrrr}
\toprule
                 &          &  Sample Size: 1 &  Sample Size: 2 &  Sample Size: 3 &  Sample Size: 4 &  Sample Size: 5 &  Sample Size: 10 \\
Feature Type & Metric &                  &                  &                  &                  &                  &                   \\
\midrule
numeric & accuracy &         0.951134 &         0.957179 &         0.961713 &         0.962720 &         0.961511 &          0.961713 \\
                 & precision &         0.906667 &         0.919703 &         0.925393 &         0.926550 &         0.923449 &          0.920107 \\
                 & recall &         0.961810 &         0.963932 &         0.970769 &         0.972419 &         0.972560 &          0.977369 \\
                 & f1-score &         0.933425 &         0.941298 &         0.947538 &         0.948930 &         0.947368 &          0.947874 \\
categorical & accuracy &         0.911839 &         0.922418 &         0.923090 &         0.923426 &         0.924937 &          0.921914 \\
                 & precision &         0.773256 &         0.804217 &         0.799344 &         0.805611 &         0.804830 &          0.802000 \\
                 & recall &         0.873085 &         0.876368 &         0.889132 &         0.879650 &         0.889716 &          0.877462 \\
                 & f1-score &         0.820144 &         0.838743 &         0.841851 &         0.841004 &         0.845147 &          0.838036 \\
datetime & accuracy &         0.992947 &         0.995466 &         0.996641 &         0.996474 &         0.997582 &          0.996474 \\
                 & precision &         0.956835 &         0.958333 &         0.967517 &         0.971831 &         0.982979 &          0.971831 \\
                 & recall &         0.943262 &         0.978723 &         0.985816 &         0.978723 &         0.982979 &          0.978723 \\
                 & f1-score &         0.950000 &         0.968421 &         0.976581 &         0.975265 &         0.982979 &          0.975265 \\
sentence & accuracy &         0.977834 &         0.981612 &         0.981360 &         0.981486 &         0.982267 &          0.981864 \\
                 & precision &         0.842857 &         0.853503 &         0.857143 &         0.833837 &         0.849754 &          0.825581 \\
                 & recall &         0.641304 &         0.728261 &         0.717391 &         0.750000 &         0.750000 &          0.771739 \\
                 & f1-score &         0.728395 &         0.785924 &         0.781065 &         0.789700 &         0.796767 &          0.797753 \\
url & accuracy &         0.996474 &         0.996725 &         0.998153 &         0.998363 &         0.997179 &          0.996977 \\
                 & precision &         0.931034 &         0.947368 &         0.956989 &         0.960000 &         0.958333 &          1.000000 \\
                 & recall &         0.843750 &         0.843750 &         0.927083 &         0.937500 &         0.862500 &          0.812500 \\
                 & f1-score &         0.885246 &         0.892562 &         0.941799 &         0.948617 &         0.907895 &          0.896552 \\
embedded-number & accuracy &         0.984383 &         0.985139 &         0.988413 &         0.986524 &         0.988615 &          0.988413 \\
                 & precision &         0.840000 &         0.835749 &         0.882550 &         0.858561 &         0.888211 &          0.904255 \\
                 & recall &         0.848485 &         0.873737 &         0.885522 &         0.873737 &         0.882828 &          0.858586 \\
                 & f1-score &         0.844221 &         0.854321 &         0.884034 &         0.866083 &         0.885512 &          0.880829 \\
list & accuracy &         0.985390 &         0.986146 &         0.987406 &         0.988287 &         0.989018 &          0.990932 \\
                 & precision &         0.818182 &         0.864198 &         0.869231 &         0.914110 &         0.911215 &          0.953488 \\
                 & recall &         0.631579 &         0.614035 &         0.660819 &         0.653509 &         0.684211 &          0.719298 \\
                 & f1-score &         0.712871 &         0.717949 &         0.750831 &         0.762148 &         0.781563 &          0.820000 \\
not-generalizable & accuracy &         0.927456 &         0.931234 &         0.936860 &         0.935264 &         0.933703 &          0.942569 \\
                 & precision &         0.689840 &         0.698734 &         0.727580 &         0.718434 &         0.714727 &          0.758974 \\
                 & recall &         0.600000 &         0.641860 &         0.666667 &         0.661628 &         0.645581 &          0.688372 \\
                 & f1-score &         0.641791 &         0.669091 &         0.695793 &         0.688862 &         0.678397 &          0.721951 \\
context-specific & accuracy &         0.944081 &         0.945844 &         0.948279 &         0.948363 &         0.948312 &          0.946096 \\
                 & precision &         0.746667 &         0.752443 &         0.786543 &         0.777778 &         0.776882 &          0.763514 \\
                 & recall &         0.605405 &         0.624324 &         0.610811 &         0.624324 &         0.624865 &          0.610811 \\
                 & f1-score &         0.668657 &         0.682422 &         0.687627 &         0.692654 &         0.692630 &          0.678679 \\
\bottomrule
\end{tabular}
