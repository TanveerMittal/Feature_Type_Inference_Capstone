{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b38105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from process_data import *\n",
    "from models.transformer_cnn import *\n",
    "from training import train\n",
    "from evaluation import evaluate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56e6704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record_id</th>\n",
       "      <th>Attribute_name</th>\n",
       "      <th>y_act</th>\n",
       "      <th>total_vals</th>\n",
       "      <th>num_nans</th>\n",
       "      <th>%_nans</th>\n",
       "      <th>num_of_dist_val</th>\n",
       "      <th>%_dist_val</th>\n",
       "      <th>mean</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_stopword_total</th>\n",
       "      <th>stdev_stopword_total</th>\n",
       "      <th>mean_char_count</th>\n",
       "      <th>stdev_char_count</th>\n",
       "      <th>mean_whitespace_count</th>\n",
       "      <th>stdev_whitespace_count</th>\n",
       "      <th>mean_delim_count</th>\n",
       "      <th>stdev_delim_count</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_long_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Area</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.810169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.816638</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Area Code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.810169</td>\n",
       "      <td>125.449411</td>\n",
       "      <td>72.866452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Element</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Element Code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>5211.687154</td>\n",
       "      <td>146.816661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Item</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115</td>\n",
       "      <td>0.535457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>19.6</td>\n",
       "      <td>2.244994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record_id Attribute_name        y_act  total_vals  num_nans  %_nans  \\\n",
       "0         33           Area  categorical       21477         0     0.0   \n",
       "1         33      Area Code  categorical       21477         0     0.0   \n",
       "2         33        Element  categorical       21477         0     0.0   \n",
       "3         33   Element Code  categorical       21477         0     0.0   \n",
       "4         33           Item  categorical       21477         0     0.0   \n",
       "\n",
       "   num_of_dist_val  %_dist_val         mean     std_dev  ...  \\\n",
       "0              174    0.810169     0.000000    0.000000  ...   \n",
       "1              174    0.810169   125.449411   72.866452  ...   \n",
       "2                2    0.009312     0.000000    0.000000  ...   \n",
       "3                2    0.009312  5211.687154  146.816661  ...   \n",
       "4              115    0.535457     0.000000    0.000000  ...   \n",
       "\n",
       "   mean_stopword_total  stdev_stopword_total mean_char_count stdev_char_count  \\\n",
       "0                  0.2                   0.4            10.0         4.816638   \n",
       "1                  0.0                   0.0             1.0         0.000000   \n",
       "2                  0.0                   0.0             4.0         0.000000   \n",
       "3                  0.0                   0.0             4.0         0.000000   \n",
       "4                  0.8                   0.4            19.6         2.244994   \n",
       "\n",
       "  mean_whitespace_count stdev_whitespace_count mean_delim_count  \\\n",
       "0                   0.4                    0.8              0.4   \n",
       "1                   0.0                    0.0              0.0   \n",
       "2                   0.0                    0.0              0.0   \n",
       "3                   0.0                    0.0              0.0   \n",
       "4                   2.0                    0.0              2.0   \n",
       "\n",
       "   stdev_delim_count  is_list  is_long_sentence  \n",
       "0                0.8    False             False  \n",
       "1                0.0    False             False  \n",
       "2                0.0    False             False  \n",
       "3                0.0    False             False  \n",
       "4                0.0    False             False  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zoo_train, df_zoo_test = load_data(\"../data\")\n",
    "df_zoo_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9965ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Area [SEP] Afghanistan [SEP] Albania [SEP] Alg...</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Area Code [SEP] 2 [SEP] 3 [SEP] 4 [SEP] 7 [SEP] 8</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Element [SEP] Food [SEP] Feed [SEP] Food [SEP]...</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Element Code [SEP] 5142 [SEP] 5521 [SEP] 5142 ...</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Item [SEP] Wheat and products [SEP] Rice (Mill...</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Area [SEP] Afghanistan [SEP] Albania [SEP] Alg...   \n",
       "1  Area Code [SEP] 2 [SEP] 3 [SEP] 4 [SEP] 7 [SEP] 8   \n",
       "2  Element [SEP] Food [SEP] Feed [SEP] Food [SEP]...   \n",
       "3  Element Code [SEP] 5142 [SEP] 5521 [SEP] 5142 ...   \n",
       "4  Item [SEP] Wheat and products [SEP] Rice (Mill...   \n",
       "\n",
       "                                            features  label  \n",
       "0  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  \n",
       "1  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  \n",
       "2  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  \n",
       "3  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  \n",
       "4  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = preprocess(df_zoo_train)\n",
    "test_data = preprocess(df_zoo_test)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dcc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train_data[['text', \"features\"]], train_data['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc1a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a281d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert_cnn_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b266e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f834770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "238d0393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamittal/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2198: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = init_dataloaders(x_train, y_train, x_val, y_val, \n",
    "                                                                     test_data, model=\"bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a098ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_cnn(nn.Module):\n",
    "\n",
    "    def __init__(self, bert, num_kernels, kernel_sizes):\n",
    "\n",
    "        super(BERT_cnn, self).__init__()\n",
    "\n",
    "        self.bert = bert \n",
    "    \n",
    "        Co = num_kernels\n",
    "        Ks = kernel_sizes\n",
    "        \n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, 768)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "          \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co + 19, 9)\n",
    "        \n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask, features):\n",
    "\n",
    "        #pass the inputs to the model \n",
    "        bert_out = self.bert(sent_id, attention_mask=mask)\n",
    "        \n",
    "        x = bert_out.last_hidden_state\n",
    "        \n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
    "        \n",
    "        x = torch.cat(x, 1)\n",
    "        \n",
    "        x = torch.cat([x, features], 1)\n",
    "        \n",
    "        x = self.dropout(x)  \n",
    "        \n",
    "        x = self.fc1(x)  \n",
    "        \n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876f07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_cnn(bert, 512, [1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7df9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.3034519  0.47585845 1.64387464 3.05291005 7.66545894 1.88059259\n",
      " 4.63961988 1.00890161 1.25261496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamittal/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass classes=[0. 1. 2. 3. 4. 5. 6. 7. 8.], y=7476    6.0\n",
      "1834    1.0\n",
      "7213    5.0\n",
      "500     0.0\n",
      "1015    7.0\n",
      "       ... \n",
      "2251    0.0\n",
      "3105    2.0\n",
      "5948    8.0\n",
      "1403    1.0\n",
      "357     0.0\n",
      "Name: label, Length: 6347, dtype: float64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2593402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30a31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57de81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-6)\n",
    "# number of training epochs\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36601513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.154\n",
      "Validation Loss: 0.267\n",
      "Validation Accuracy: 0.904\n",
      "\n",
      " Epoch 2 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.151\n",
      "Validation Loss: 0.266\n",
      "Validation Accuracy: 0.900\n",
      "\n",
      " Epoch 3 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.147\n",
      "Validation Loss: 0.265\n",
      "Validation Accuracy: 0.900\n",
      "\n",
      " Epoch 4 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.161\n",
      "Validation Loss: 0.264\n",
      "Validation Accuracy: 0.904\n",
      "\n",
      " Epoch 5 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.149\n",
      "Validation Loss: 0.265\n",
      "Validation Accuracy: 0.905\n",
      "\n",
      " Epoch 6 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.149\n",
      "Validation Loss: 0.265\n",
      "Validation Accuracy: 0.902\n",
      "\n",
      " Epoch 7 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.154\n",
      "Validation Loss: 0.264\n",
      "Validation Accuracy: 0.902\n",
      "\n",
      " Epoch 8 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.147\n",
      "Validation Loss: 0.265\n",
      "Validation Accuracy: 0.904\n",
      "\n",
      " Epoch 9 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.144\n",
      "Validation Loss: 0.263\n",
      "Validation Accuracy: 0.904\n",
      "\n",
      " Epoch 10 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.141\n",
      "Validation Loss: 0.264\n",
      "Validation Accuracy: 0.900\n",
      "\n",
      " Epoch 11 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.141\n",
      "Validation Loss: 0.263\n",
      "Validation Accuracy: 0.900\n",
      "\n",
      " Epoch 12 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.158\n",
      "Validation Loss: 0.262\n",
      "Validation Accuracy: 0.902\n",
      "\n",
      " Epoch 13 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.149\n",
      "Validation Loss: 0.264\n",
      "Validation Accuracy: 0.909\n",
      "\n",
      " Epoch 14 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.173\n",
      "Validation Loss: 0.262\n",
      "Validation Accuracy: 0.911\n",
      "\n",
      " Epoch 15 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.166\n",
      "Validation Loss: 0.262\n",
      "Validation Accuracy: 0.911\n",
      "\n",
      " Epoch 16 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.141\n",
      "Validation Loss: 0.261\n",
      "Validation Accuracy: 0.905\n",
      "\n",
      " Epoch 17 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.140\n",
      "Validation Loss: 0.261\n",
      "Validation Accuracy: 0.904\n",
      "\n",
      " Epoch 18 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.150\n",
      "Validation Loss: 0.260\n",
      "Validation Accuracy: 0.907\n",
      "\n",
      " Epoch 19 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.139\n",
      "Validation Loss: 0.262\n",
      "Validation Accuracy: 0.910\n",
      "\n",
      " Epoch 20 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.147\n",
      "Validation Loss: 0.263\n",
      "Validation Accuracy: 0.909\n",
      "\n",
      " Epoch 21 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.136\n",
      "Validation Loss: 0.261\n",
      "Validation Accuracy: 0.905\n",
      "\n",
      " Epoch 22 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.136\n",
      "Validation Loss: 0.263\n",
      "Validation Accuracy: 0.905\n",
      "\n",
      " Epoch 23 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.144\n",
      "Validation Loss: 0.262\n",
      "Validation Accuracy: 0.911\n",
      "\n",
      " Epoch 24 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.135\n",
      "Validation Loss: 0.261\n",
      "Validation Accuracy: 0.909\n",
      "\n",
      " Epoch 25 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.138\n",
      "Validation Loss: 0.264\n",
      "Validation Accuracy: 0.913\n"
     ]
    }
   ],
   "source": [
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _, = train(model, train_dataloader, optimizer, cross_entropy)\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _, valid_acc = evaluate(model, val_dataloader, cross_entropy, y_val)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../models/exports/%s.pt' % model_name)\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n",
    "    print(f'Validation Accuracy: {valid_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40fb4577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4a93f92fa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(valid_losses)\n",
    "plt.legend([\"train\", \"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36fee864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "  Batch    50  of     63.\n",
      "test_accuracy: 0.9073047858942066\n"
     ]
    }
   ],
   "source": [
    "loss, preds, acc = evaluate(model,test_dataloader, cross_entropy, test_data[\"label\"])\n",
    "print(\"test_accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a04cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
