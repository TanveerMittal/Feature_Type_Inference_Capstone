{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b38105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from process_data import *\n",
    "from models.transformer_cnn import *\n",
    "from training import train\n",
    "from evaluation import evaluate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56e6704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record_id</th>\n",
       "      <th>Attribute_name</th>\n",
       "      <th>y_act</th>\n",
       "      <th>total_vals</th>\n",
       "      <th>num_nans</th>\n",
       "      <th>%_nans</th>\n",
       "      <th>num_of_dist_val</th>\n",
       "      <th>%_dist_val</th>\n",
       "      <th>mean</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_stopword_total</th>\n",
       "      <th>stdev_stopword_total</th>\n",
       "      <th>mean_char_count</th>\n",
       "      <th>stdev_char_count</th>\n",
       "      <th>mean_whitespace_count</th>\n",
       "      <th>stdev_whitespace_count</th>\n",
       "      <th>mean_delim_count</th>\n",
       "      <th>stdev_delim_count</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_long_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Area</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.810169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.816638</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Area Code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.810169</td>\n",
       "      <td>125.449411</td>\n",
       "      <td>72.866452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Element</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Element Code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>5211.687154</td>\n",
       "      <td>146.816661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Item</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21477</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115</td>\n",
       "      <td>0.535457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>19.6</td>\n",
       "      <td>2.244994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record_id Attribute_name        y_act  total_vals  num_nans  %_nans  \\\n",
       "0         33           Area  categorical       21477         0     0.0   \n",
       "1         33      Area Code  categorical       21477         0     0.0   \n",
       "2         33        Element  categorical       21477         0     0.0   \n",
       "3         33   Element Code  categorical       21477         0     0.0   \n",
       "4         33           Item  categorical       21477         0     0.0   \n",
       "\n",
       "   num_of_dist_val  %_dist_val         mean     std_dev  ...  \\\n",
       "0              174    0.810169     0.000000    0.000000  ...   \n",
       "1              174    0.810169   125.449411   72.866452  ...   \n",
       "2                2    0.009312     0.000000    0.000000  ...   \n",
       "3                2    0.009312  5211.687154  146.816661  ...   \n",
       "4              115    0.535457     0.000000    0.000000  ...   \n",
       "\n",
       "   mean_stopword_total  stdev_stopword_total mean_char_count stdev_char_count  \\\n",
       "0                  0.2                   0.4            10.0         4.816638   \n",
       "1                  0.0                   0.0             1.0         0.000000   \n",
       "2                  0.0                   0.0             4.0         0.000000   \n",
       "3                  0.0                   0.0             4.0         0.000000   \n",
       "4                  0.8                   0.4            19.6         2.244994   \n",
       "\n",
       "  mean_whitespace_count stdev_whitespace_count mean_delim_count  \\\n",
       "0                   0.4                    0.8              0.4   \n",
       "1                   0.0                    0.0              0.0   \n",
       "2                   0.0                    0.0              0.0   \n",
       "3                   0.0                    0.0              0.0   \n",
       "4                   2.0                    0.0              2.0   \n",
       "\n",
       "   stdev_delim_count  is_list  is_long_sentence  \n",
       "0                0.8    False             False  \n",
       "1                0.0    False             False  \n",
       "2                0.0    False             False  \n",
       "3                0.0    False             False  \n",
       "4                0.0    False             False  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zoo_train, df_zoo_test = load_data(\"../data\")\n",
    "df_zoo_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9965ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Area&lt;sep&gt;Afghanistan&lt;sep&gt;Albania&lt;sep&gt;Algeria&lt;s...</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Area Code&lt;sep&gt;2&lt;sep&gt;3&lt;sep&gt;4&lt;sep&gt;7&lt;sep&gt;8</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Element&lt;sep&gt;Food&lt;sep&gt;Feed&lt;sep&gt;Food&lt;sep&gt;Food&lt;se...</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Element Code&lt;sep&gt;5142&lt;sep&gt;5521&lt;sep&gt;5142&lt;sep&gt;51...</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Item&lt;sep&gt;Wheat and products&lt;sep&gt;Rice (Milled E...</td>\n",
       "      <td>[1.058161729698188, -0.49520412160069144, 0.0,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Area<sep>Afghanistan<sep>Albania<sep>Algeria<s...   \n",
       "1            Area Code<sep>2<sep>3<sep>4<sep>7<sep>8   \n",
       "2  Element<sep>Food<sep>Feed<sep>Food<sep>Food<se...   \n",
       "3  Element Code<sep>5142<sep>5521<sep>5142<sep>51...   \n",
       "4  Item<sep>Wheat and products<sep>Rice (Milled E...   \n",
       "\n",
       "                                            features  label  \n",
       "0  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  \n",
       "1  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  \n",
       "2  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  \n",
       "3  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  \n",
       "4  [1.058161729698188, -0.49520412160069144, 0.0,...    1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = preprocess(df_zoo_train, \"<sep>\")\n",
    "test_data = preprocess(df_zoo_test, \"<sep>\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dcc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train_data[['text', \"features\"]], train_data['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc1a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a281d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xlnet_cnn_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b266e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f834770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in transformer.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "238d0393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamittal/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2198: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = init_dataloaders(x_train, y_train, x_val, y_val,\n",
    "                                                                          test_data, model=\"xlnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "876f07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer_cnn(transformer, 256, [2, 3, 4])\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e7df9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.3034519  0.47585845 1.64387464 3.05291005 7.66545894 1.88059259\n",
      " 4.63961988 1.00890161 1.25261496]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2593402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e30a31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e29575da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5)\n",
    "# number of training epochs\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36601513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 1.070\n",
      "Validation Loss: 1.250\n",
      "Validation Accuracy: 0.730\n",
      "\n",
      " Epoch 2 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.972\n",
      "Validation Loss: 1.196\n",
      "Validation Accuracy: 0.744\n",
      "\n",
      " Epoch 3 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.894\n",
      "Validation Loss: 1.148\n",
      "Validation Accuracy: 0.754\n",
      "\n",
      " Epoch 4 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.791\n",
      "Validation Loss: 1.126\n",
      "Validation Accuracy: 0.750\n",
      "\n",
      " Epoch 5 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.809\n",
      "Validation Loss: 1.117\n",
      "Validation Accuracy: 0.746\n",
      "\n",
      " Epoch 6 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.818\n",
      "Validation Loss: 1.065\n",
      "Validation Accuracy: 0.757\n",
      "\n",
      " Epoch 7 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.749\n",
      "Validation Loss: 1.066\n",
      "Validation Accuracy: 0.760\n",
      "\n",
      " Epoch 8 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.743\n",
      "Validation Loss: 1.022\n",
      "Validation Accuracy: 0.774\n",
      "\n",
      " Epoch 9 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.660\n",
      "Validation Loss: 1.010\n",
      "Validation Accuracy: 0.784\n",
      "\n",
      " Epoch 10 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.666\n",
      "Validation Loss: 0.989\n",
      "Validation Accuracy: 0.781\n",
      "\n",
      " Epoch 11 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.667\n",
      "Validation Loss: 0.976\n",
      "Validation Accuracy: 0.775\n",
      "\n",
      " Epoch 12 / 25\n",
      "  Batch    50  of    199.\n",
      "  Batch   100  of    199.\n",
      "  Batch   150  of    199.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.637\n",
      "Validation Loss: 0.964\n",
      "Validation Accuracy: 0.765\n",
      "\n",
      " Epoch 13 / 25\n",
      "  Batch    50  of    199.\n"
     ]
    }
   ],
   "source": [
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _, = train(model, train_dataloader, optimizer, cross_entropy)\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _, valid_acc = evaluate(model, val_dataloader, cross_entropy, y_val)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../models/exports/%s.pt' % model_name)\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n",
    "    print(f'Validation Accuracy: {valid_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb4577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(valid_losses)\n",
    "plt.legend([\"train\", \"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fee864",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, preds, acc = evaluate(model, test_dataloader, cross_entropy, test_data[\"label\"])\n",
    "print(\"test_accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"../models/exports/xlnet_cnn_v1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a3464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
